{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNfLgUpEjBIwIp/6sIQuLD3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abidt2002/AI-EduMaster-Platform/blob/main/AI_EduMaster_Platform.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hgb_XHEFtMwz",
        "outputId": "e50e486d-7d42-49bd-b96a-5f3d4c253341"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.12/dist-packages (1.50.0)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.12/dist-packages (7.4.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.2)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.1)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.12/dist-packages (6.1.1)\n",
            "Requirement already satisfied: bcrypt in /usr/local/lib/python3.12/dist-packages (5.0.0)\n",
            "Requirement already satisfied: sqlite-utils in /usr/local/lib/python3.12/dist-packages (3.38)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.10.1)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.12/dist-packages (0.48.1)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.0)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.35.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.77)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.31)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.9)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.43)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.8.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.2)\n",
            "Requirement already satisfied: sqlite-fts4 in /usr/local/lib/python3.12/dist-packages (from sqlite-utils) (1.0.3)\n",
            "Requirement already satisfied: click-default-group>=1.2.3 in /usr/local/lib/python3.12/dist-packages (from sqlite-utils) (1.2.4)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (from sqlite-utils) (0.9.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from sqlite-utils) (2.9.0.post0)\n",
            "Requirement already satisfied: pluggy in /usr/local/lib/python3.12/dist-packages (from sqlite-utils) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.6.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.25.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil->sqlite-utils) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.27.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit pyngrok transformers langchain faiss-cpu sentence-transformers pypdf bcrypt sqlite-utils accelerate bitsandbytes\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass, os, subprocess\n",
        "\n",
        "# ðŸ”’ Step 1: Enter your real ngrok token securely (it will stay hidden)\n",
        "NGROK_AUTH_TOKEN = getpass.getpass(\"Enter your real ngrok authtoken (hidden): \")\n",
        "\n",
        "# ðŸ”’ Step 2: Store it temporarily and configure ngrok silently\n",
        "os.environ[\"NGROK_AUTH_TOKEN\"] = NGROK_AUTH_TOKEN\n",
        "subprocess.run([\"ngrok\", \"config\", \"add-authtoken\", NGROK_AUTH_TOKEN], stdout=subprocess.DEVNULL)\n",
        "print(\"âœ… ngrok token configured securely!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOk3hPKCu_OI",
        "outputId": "cbbf8ee0-8294-4a8e-de2e-8d493a3ecab6"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your real ngrok authtoken (hidden): Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "âœ… ngrok token configured securely!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "ngrok.kill()\n",
        "public_url = ngrok.connect(8501)\n",
        "print(\"ðŸŒ Your Live App Link:\", public_url)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdoumxuPt7kP",
        "outputId": "c7f3885d-c389-4c51-937c-016b57ba90c3"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸŒ Your Live App Link: NgrokTunnel: \"https://fcb4fa93a75c.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import sqlite3, bcrypt, os, time, pickle, numpy as np\n",
        "from datetime import datetime\n",
        "from pypdf import PdfReader\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "from transformers import pipeline\n",
        "\n",
        "# ----- Config -----\n",
        "DATA_DIR = \"data\"\n",
        "DB_DIR = \"db\"\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "os.makedirs(DB_DIR, exist_ok=True)\n",
        "\n",
        "# ----- Models (load once) -----\n",
        "@st.cache_resource\n",
        "def load_models():\n",
        "    emb_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "    qa_pipe = pipeline(\"text2text-generation\", model=\"google/flan-t5-base\", device_map=\"auto\" if False else None)\n",
        "    summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "    return emb_model, qa_pipe, summarizer\n",
        "\n",
        "emb_model, qa_pipe, summarizer = load_models()\n",
        "\n",
        "# ----- DB Setup -----\n",
        "conn = sqlite3.connect(os.path.join(DB_DIR, \"users_activities.db\"), check_same_thread=False)\n",
        "cur = conn.cursor()\n",
        "cur.execute(\"\"\"CREATE TABLE IF NOT EXISTS users (\n",
        "    username TEXT PRIMARY KEY,\n",
        "    password BLOB NOT NULL,\n",
        "    role TEXT NOT NULL\n",
        ")\"\"\")\n",
        "cur.execute(\"\"\"CREATE TABLE IF NOT EXISTS activities (\n",
        "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    timestamp TEXT,\n",
        "    username TEXT,\n",
        "    role TEXT,\n",
        "    action TEXT,\n",
        "    details TEXT\n",
        ")\"\"\")\n",
        "conn.commit()\n",
        "\n",
        "# ----- Utilities -----\n",
        "def log_activity(username, role, action, details=\"\"):\n",
        "    cur.execute(\"INSERT INTO activities (timestamp, username, role, action, details) VALUES (?, ?, ?, ?, ?)\",\n",
        "                (datetime.utcnow().isoformat(), username, role, action, details))\n",
        "    conn.commit()\n",
        "\n",
        "def hash_password(password: str):\n",
        "    return bcrypt.hashpw(password.encode(), bcrypt.gensalt())\n",
        "\n",
        "def verify_password(password: str, hashed: bytes):\n",
        "    return bcrypt.checkpw(password.encode(), hashed)\n",
        "\n",
        "def add_user(username, password, role):\n",
        "    cur.execute(\"INSERT INTO users (username, password, role) VALUES (?, ?, ?)\", (username, hash_password(password), role))\n",
        "    conn.commit()\n",
        "\n",
        "def authenticate(username, password):\n",
        "    cur.execute(\"SELECT password, role FROM users WHERE username=?\", (username,))\n",
        "    row = cur.fetchone()\n",
        "    if row and verify_password(password, row[0]):\n",
        "        return row[1]\n",
        "    return None\n",
        "\n",
        "# ----- Vector store helpers (per teacher) -----\n",
        "# We store for each teacher: index file (faiss) + metadata list (texts)\n",
        "def _chunks_from_text(text, chunk_size=800, overlap=100):\n",
        "    chunks = []\n",
        "    i = 0\n",
        "    while i < len(text):\n",
        "        chunk = text[i:i+chunk_size]\n",
        "        chunks.append(chunk)\n",
        "        i += chunk_size - overlap\n",
        "    return chunks\n",
        "\n",
        "def extract_text_from_pdf(path):\n",
        "    text = \"\"\n",
        "    reader = PdfReader(path)\n",
        "    for p in reader.pages:\n",
        "        try:\n",
        "            t = p.extract_text()\n",
        "            if t:\n",
        "                text += \"\\n\" + t\n",
        "        except:\n",
        "            continue\n",
        "    return text\n",
        "\n",
        "def build_teacher_index(username, filepath):\n",
        "    # extract\n",
        "    fulltext = extract_text_from_pdf(filepath)\n",
        "    chunks = _chunks_from_text(fulltext)\n",
        "    # embeddings\n",
        "    embeddings = emb_model.encode(chunks, show_progress_bar=False, convert_to_numpy=True)\n",
        "    # normalize for cosine\n",
        "    faiss.normalize_L2(embeddings)\n",
        "    dim = embeddings.shape[1]\n",
        "    index = faiss.IndexFlatIP(dim)\n",
        "    index.add(embeddings)\n",
        "    # save index and metadata\n",
        "    idx_path = os.path.join(DATA_DIR, f\"{username}_index.faiss\")\n",
        "    faiss.write_index(index, idx_path)\n",
        "    meta_path = os.path.join(DATA_DIR, f\"{username}_meta.pkl\")\n",
        "    with open(meta_path, \"wb\") as f:\n",
        "        pickle.dump(chunks, f)\n",
        "    return True\n",
        "\n",
        "def load_teacher_index(username):\n",
        "    idx_path = os.path.join(DATA_DIR, f\"{username}_index.faiss\")\n",
        "    meta_path = os.path.join(DATA_DIR, f\"{username}_meta.pkl\")\n",
        "    if not os.path.exists(idx_path) or not os.path.exists(meta_path):\n",
        "        return None, None\n",
        "    index = faiss.read_index(idx_path)\n",
        "    with open(meta_path, \"rb\") as f:\n",
        "        chunks = pickle.load(f)\n",
        "    return index, chunks\n",
        "\n",
        "def teacher_similarity_search(username, query, top_k=3):\n",
        "    index, chunks = load_teacher_index(username)\n",
        "    if index is None:\n",
        "        return []\n",
        "    q_emb = emb_model.encode([query], convert_to_numpy=True)\n",
        "    faiss.normalize_L2(q_emb)\n",
        "    D, I = index.search(q_emb, top_k)\n",
        "    results = []\n",
        "    for idx in I[0]:\n",
        "        if idx < len(chunks):\n",
        "            results.append(chunks[idx])\n",
        "    return results\n",
        "\n",
        "# ----- Streams / UI -----\n",
        "st.set_page_config(page_title=\"AI Education Platform\", layout=\"wide\")\n",
        "st.title(\"ðŸŽ“ AI-Powered Educational Platform (Colab)\")\n",
        "\n",
        "menu = [\"Login\", \"Register\"]\n",
        "choice = st.sidebar.selectbox(\"Menu\", menu)\n",
        "\n",
        "if \"username\" not in st.session_state:\n",
        "    st.session_state.username = None\n",
        "if \"role\" not in st.session_state:\n",
        "    st.session_state.role = None\n",
        "\n",
        "# ----- Register -----\n",
        "if choice == \"Register\":\n",
        "    st.subheader(\"Create a new account\")\n",
        "    new_user = st.text_input(\"Username\")\n",
        "    new_pass = st.text_input(\"Password\", type=\"password\")\n",
        "    role = st.selectbox(\"Role\", [\"Student\", \"Teacher\", \"Admin\"])\n",
        "    if st.button(\"Register\"):\n",
        "        try:\n",
        "            add_user(new_user, new_pass, role)\n",
        "            st.success(\"âœ… Account created. Please login.\")\n",
        "            log_activity(new_user, role, \"register\", \"\")\n",
        "        except Exception as e:\n",
        "            st.error(\"Username already exists or invalid. \" + str(e))\n",
        "\n",
        "# ----- Login -----\n",
        "elif choice == \"Login\":\n",
        "    st.subheader(\"Login\")\n",
        "    username = st.text_input(\"Username\")\n",
        "    password = st.text_input(\"Password\", type=\"password\")\n",
        "    if st.button(\"Login\"):\n",
        "        role = authenticate(username, password)\n",
        "        if role:\n",
        "            st.session_state.username = username\n",
        "            st.session_state.role = role\n",
        "            st.success(f\"Welcome {username} ({role})\")\n",
        "            log_activity(username, role, \"login\", \"\")\n",
        "        else:\n",
        "            st.error(\"âŒ Invalid username or password\")\n",
        "\n",
        "# ----- Dashboards -----\n",
        "if st.session_state.role == \"Teacher\":\n",
        "    username = st.session_state.username\n",
        "    st.header(f\"ðŸ‘©â€ðŸ« Teacher Dashboard â€” {username}\")\n",
        "\n",
        "    st.subheader(\"Upload Study Material (PDF)\")\n",
        "    uploaded = st.file_uploader(\"Upload one or more PDFs\", type=[\"pdf\"], accept_multiple_files=True)\n",
        "    if uploaded:\n",
        "        for up in uploaded:\n",
        "            save_path = os.path.join(DATA_DIR, f\"{username}__{up.name}\")\n",
        "            with open(save_path, \"wb\") as f:\n",
        "                f.write(up.getbuffer())\n",
        "            # build index for this file (append to teacher index: for simplicity we rebuild using the latest file only)\n",
        "            # For production you may merge all teacher files; here we rebuild from latest file\n",
        "            build_teacher_index(username, save_path)\n",
        "            st.success(f\"Saved and indexed: {up.name}\")\n",
        "            log_activity(username, \"Teacher\", \"upload\", up.name)\n",
        "\n",
        "    st.subheader(\"AI Tools\")\n",
        "    # Summarize prompt\n",
        "    summary_q = st.text_input(\"Ask the system to summarize (e.g. 'Summarize chapter 1'):\")\n",
        "    if st.button(\"Summarize from uploaded material\") and summary_q:\n",
        "        ctxs = teacher_similarity_search(username, summary_q, top_k=3)\n",
        "        if not ctxs:\n",
        "            st.warning(\"No teacher material indexed yet. Please upload PDFs above.\")\n",
        "        else:\n",
        "            ctx = \"\\n\".join(ctxs)\n",
        "            prompt = f\"Summarize the following content in 3-6 sentences:\\n\\n{ctx}\"\n",
        "            res = summarizer(prompt, max_length=200, truncation=True)\n",
        "            out = res[0][\"summary_text\"]\n",
        "            st.text_area(\"Summary\", out, height=200)\n",
        "            log_activity(username, \"Teacher\", \"summarize\", summary_q)\n",
        "\n",
        "    # Generate Quiz\n",
        "    quiz_topic = st.text_input(\"Enter a topic (or keyword) to generate 5 MCQs:\")\n",
        "    if st.button(\"Generate Quiz\") and quiz_topic:\n",
        "        ctxs = teacher_similarity_search(username, quiz_topic, top_k=3)\n",
        "        if not ctxs:\n",
        "            st.warning(\"No teacher material indexed yet. Please upload PDFs.\")\n",
        "        else:\n",
        "            ctx = \"\\n\".join(ctxs)\n",
        "            q_prompt = (f\"Based on the content below, generate 5 multiple-choice questions (each with 4 options \"\n",
        "                        f\"and indicate the correct option) about: {quiz_topic}\\n\\nContent:\\n{ctx}\\n\\nOutput format:\\n1) Q? \\nA) ... B) ... C) ... D) ... Answer: B\\n...\")\n",
        "            res = qa_pipe(q_prompt, max_length=512)\n",
        "            quiz_text = res[0][\"generated_text\"]\n",
        "            st.text_area(\"AI Generated Quiz (raw)\", quiz_text, height=300)\n",
        "            # Save quiz to disk\n",
        "            qfile = os.path.join(\"data\", f\"{username}__quiz__{int(time.time())}.txt\")\n",
        "            with open(qfile, \"w\") as f:\n",
        "                f.write(quiz_text)\n",
        "            log_activity(username, \"Teacher\", \"generate_quiz\", quiz_topic)\n",
        "\n",
        "    # View teacher's indexed status\n",
        "    idx, meta = load_teacher_index(username)\n",
        "    if idx is None:\n",
        "        st.info(\"No index found yet for your uploads.\")\n",
        "    else:\n",
        "        st.success(\"âœ… Your material is indexed and ready for Student queries.\")\n",
        "\n",
        "    # Optionally list uploaded files\n",
        "    st.subheader(\"Uploaded files\")\n",
        "    files = [f for f in os.listdir(DATA_DIR) if f.startswith(username + \"__\")]\n",
        "    st.write(files)\n",
        "\n",
        "elif st.session_state.role == \"Student\":\n",
        "    username = st.session_state.username\n",
        "    st.header(f\"ðŸŽ“ Student Dashboard â€” {username}\")\n",
        "    st.subheader(\"Ask a question from your teacher's material\")\n",
        "    teacher_name = st.text_input(\"Enter teacher username to query (exact):\")\n",
        "    question = st.text_input(\"Your question (e.g. 'Summarize chapter 1'):\")\n",
        "    if st.button(\"Ask\") and teacher_name and question:\n",
        "        idx, meta = load_teacher_index(teacher_name)\n",
        "        if idx is None:\n",
        "            st.error(\"That teacher has not uploaded or indexed any material yet.\")\n",
        "        else:\n",
        "            # combine top contexts\n",
        "            ctxs = teacher_similarity_search(teacher_name, question, top_k=3)\n",
        "            ctx = \"\\n\".join(ctxs)\n",
        "            prompt = f\"Context: {ctx}\\n\\nQuestion: {question}\\nAnswer concisely:\"\n",
        "            res = qa_pipe(prompt, max_length=256)\n",
        "            ans = res[0][\"generated_text\"]\n",
        "            st.text_area(\"AI Answer\", ans, height=200)\n",
        "            log_activity(username, \"Student\", \"ask_question\", f\"teacher={teacher_name}; q={question}\")\n",
        "\n",
        "    st.subheader(\"Practice Quizzes (auto-generated)\")\n",
        "    # list quizzes for all teachers (simple)\n",
        "    qlist = [f for f in os.listdir(DATA_DIR) if \"__quiz__\" in f]\n",
        "    if qlist:\n",
        "        chosen = st.selectbox(\"Select a quiz file\", qlist)\n",
        "        if st.button(\"Load Quiz\"):\n",
        "            with open(os.path.join(DATA_DIR, chosen), \"r\") as f:\n",
        "                st.text_area(\"Quiz content\", f.read(), height=300)\n",
        "            log_activity(username, \"Student\", \"load_quiz\", chosen)\n",
        "    else:\n",
        "        st.info(\"No quizzes available yet. Ask your teacher to generate one.\")\n",
        "\n",
        "elif st.session_state.role == \"Admin\":\n",
        "    username = st.session_state.username\n",
        "    st.header(\"ðŸ§‘â€ðŸ’¼ Admin Dashboard\")\n",
        "    st.subheader(\"Users\")\n",
        "    cur.execute(\"SELECT username, role FROM users\")\n",
        "    users = cur.fetchall()\n",
        "    st.table(users)\n",
        "\n",
        "    st.subheader(\"Activity Logs (most recent 200)\")\n",
        "    cur.execute(\"SELECT timestamp, username, role, action, details FROM activities ORDER BY id DESC LIMIT 200\")\n",
        "    logs = cur.fetchall()\n",
        "    st.dataframe(logs)\n",
        "\n",
        "    # Optionally download logs\n",
        "    if st.button(\"Export logs to file\"):\n",
        "        outp = os.path.join(DB_DIR, \"activities_export.csv\")\n",
        "        import csv\n",
        "        with open(outp, \"w\", newline='') as csvfile:\n",
        "            writer = csv.writer(csvfile)\n",
        "            writer.writerow([\"timestamp\", \"username\", \"role\", \"action\", \"details\"])\n",
        "            writer.writerows(logs)\n",
        "        st.success(f\"Exported to {outp}\")\n",
        "\n",
        "else:\n",
        "    st.info(\"Please Login or Register from the sidebar. Roles available: Student, Teacher, Admin\")\n",
        "    st.write(\"Recommended demo flow:\")\n",
        "    st.write(\"1) Register a Teacher account and upload a PDF in Teacher dashboard.\")\n",
        "    st.write(\"2) Register a Student account and query that teacher's material.\")\n",
        "\n",
        "st.sidebar.markdown(\"---\")\n",
        "st.sidebar.caption(\"Secure role-based AI Education â€¢ HF models â€¢ FAISS local retrieval\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZC8JbLovz2e",
        "outputId": "8c44bab0-5649-4a6a-e202-933d92b5cf10"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# start streamlit (background)\n",
        "get_ipython().system_raw(\"streamlit run app.py &\")\n",
        "\n",
        "# connect ngrok and print URL\n",
        "from pyngrok import ngrok\n",
        "ngrok.kill()\n",
        "public_url = ngrok.connect(8501)\n",
        "print(\"ðŸŒ Your public URL ->\", public_url)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRdGKFzCwbtV",
        "outputId": "e7a87ed6-2a2d-45ce-8a7c-89064d0277bd"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸŒ Your public URL -> NgrokTunnel: \"https://806a2076fce7.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    }
  ]
}